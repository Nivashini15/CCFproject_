{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "315d90fc-06e1-4f99-987b-30837586526a",
    "_uuid": "bf775109c304a96f3b7f1661016d3c075a61344b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd #To hand with data \n",
    "import numpy as np #To math \n",
    "import seaborn as sns #to visualization\n",
    "import matplotlib.pyplot as plt # to plot the graphs\n",
    "import matplotlib.gridspec as gridspec # to do the grid of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f5ed2e58-2c04-45b9-8b64-a5fd9a211d51",
    "_uuid": "f1c7b54c4dc02147ce064826491c8b678f13a358"
   },
   "outputs": [],
   "source": [
    "#loading the data\n",
    "df_credit = pd.read_csv(\"../input/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d102b02e-6bcf-412c-9eef-fb6aecace766",
    "_uuid": "90de510bdbadedd87abdc59575b62a396b1c1e8b"
   },
   "outputs": [],
   "source": [
    "#looking the how data looks\n",
    "df_credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ddd5b399-18a1-4f81-873b-b97d2be23f67",
    "_uuid": "56f1c343acf06abb567c5909521334e5adc57308"
   },
   "outputs": [],
   "source": [
    "#looking the type and searching for null values\n",
    "df_credit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6c26e0db-71da-413b-85e9-5618851fe465",
    "_uuid": "8566d352da4e500f1a64e14e660adfe9cea2910f"
   },
   "outputs": [],
   "source": [
    "# The data is stardarized, I will explore them later\n",
    "#For now I will look the \"normal\" columns\n",
    "df_credit[[\"Time\",\"Amount\",\"Class\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b3220b5c-f3db-4553-9a76-ccb1347d5291",
    "_uuid": "af843d503f5b3f0e1b049d973ec060cee4db52d9"
   },
   "outputs": [],
   "source": [
    "#Lets start looking the difference by Normal and Fraud transactions\n",
    "print(\"Distribuition of Normal(0) and Frauds(1): \")\n",
    "print(df_credit[\"Class\"].value_counts())\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.countplot(df_credit['Class'])\n",
    "plt.title(\"Class Count\", fontsize=18)\n",
    "plt.xlabel(\"Is fraud?\", fontsize=15)\n",
    "plt.ylabel(\"Count\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1bfeb2f6bb9db6c977e7541c86c1d56616f5c227"
   },
   "source": [
    "## Time Features and some Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e7c0e7464c10ba7c24c3bdc2738e2dab895b758d"
   },
   "outputs": [],
   "source": [
    "timedelta = pd.to_timedelta(df_credit['Time'], unit='s')\n",
    "df_credit['Time_min'] = (timedelta.dt.components.minutes).astype(int)\n",
    "df_credit['Time_hour'] = (timedelta.dt.components.hours).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9fa298be-50da-4951-833b-b5b5e402dea6",
    "_uuid": "6fd743122a71a772111d9dde1ac4626750b649ab"
   },
   "outputs": [],
   "source": [
    "#Exploring the distribuition by Class types throught hours and minutes\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.distplot(df_credit[df_credit['Class'] == 0][\"Time_hour\"], \n",
    "             color='g')\n",
    "sns.distplot(df_credit[df_credit['Class'] == 1][\"Time_hour\"], \n",
    "             color='r')\n",
    "plt.title('Fraud x Normal Transactions by Hours', fontsize=17)\n",
    "plt.xlim([-1,25])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "75ea931d6404085e3559105c3f73cbffeaa38fcc"
   },
   "outputs": [],
   "source": [
    "#Exploring the distribuition by Class types throught hours and minutes\n",
    "plt.figure(figsize=(12,5))\n",
    "sns.distplot(df_credit[df_credit['Class'] == 0][\"Time_min\"], \n",
    "             color='g')\n",
    "sns.distplot(df_credit[df_credit['Class'] == 1][\"Time_min\"], \n",
    "             color='r')\n",
    "plt.title('Fraud x Normal Transactions by minutes', fontsize=17)\n",
    "plt.xlim([-1,61])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9c5da3d67e39d5497c9e5b6f01a208ec34834a84"
   },
   "source": [
    "## Looking the statistics of our Amount class frauds and normal transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3f34ae04-e6f2-4656-b1ef-478cbd9ce2e9",
    "_uuid": "b2eb4184ab7ef23938c81e260b7005a573b73199"
   },
   "outputs": [],
   "source": [
    "#To clearly the data of frauds and no frauds\n",
    "df_fraud = df_credit[df_credit['Class'] == 1]\n",
    "df_normal = df_credit[df_credit['Class'] == 0]\n",
    "\n",
    "print(\"Fraud transaction statistics\")\n",
    "print(df_fraud[\"Amount\"].describe())\n",
    "print(\"\\nNormal transaction statistics\")\n",
    "print(df_normal[\"Amount\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "555ec77171ffaeabeee44dc43565fc343595ecde"
   },
   "outputs": [],
   "source": [
    "#Feature engineering to a better visualization of the values\n",
    "df_credit['Amount_log'] = np.log(df_credit.Amount + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d9da4785-93e8-4a7d-acdc-8b5721e90532",
    "_uuid": "7a5cf2296c7e3a37cda31d2b150c8cdcc5b5ba01"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "#I will explore the Amount by Class and see the distribuition of Amount transactions\n",
    "plt.subplot(121)\n",
    "ax = sns.boxplot(x =\"Class\",y=\"Amount\",\n",
    "                 data=df_credit)\n",
    "ax.set_title(\"Class x Amount\", fontsize=20)\n",
    "ax.set_xlabel(\"Is Fraud?\", fontsize=16)\n",
    "ax.set_ylabel(\"Amount(US)\", fontsize = 16)\n",
    "\n",
    "plt.subplot(122)\n",
    "ax1 = sns.boxplot(x =\"Class\",y=\"Amount_log\", data=df_credit)\n",
    "ax1.set_title(\"Class x Amount\", fontsize=20)\n",
    "ax1.set_xlabel(\"Is Fraud?\", fontsize=16)\n",
    "ax1.set_ylabel(\"Amount(Log)\", fontsize = 16)\n",
    "\n",
    "plt.subplots_adjust(hspace = 0.6, top = 0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2866cbe93b06ceefc04748f81ac1918ecd477c3f"
   },
   "source": [
    "### Looking a scatter plot of the Time_min distribuition by Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c736e49c-15fc-4215-85e0-fccd8cb26b8c",
    "_uuid": "240895d266c51d0aa29b6d903f5facebc53cc459"
   },
   "outputs": [],
   "source": [
    "#Looking the Amount and time distribuition of FRAUD transactions\n",
    "ax = sns.lmplot(y=\"Amount\", x=\"Time_min\", fit_reg=False,aspect=1.8,\n",
    "                data=df_credit, hue='Class')\n",
    "plt.title(\"Amounts by Minutes of Frauds and Normal Transactions\",fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b3cb7168a1ac0512e676851ad73acdbf83fc2ee9"
   },
   "source": [
    "### Looking a scatter plot of the Time_hour distribuition by Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9a527a7b-d837-4d04-be9d-7808304f5306",
    "_uuid": "940ac54a36233b2d0fae60eda1618c899b40ed5f"
   },
   "outputs": [],
   "source": [
    "ax = sns.lmplot(y=\"Amount\", x=\"Time_hour\", fit_reg=False,aspect=1.8,\n",
    "                data=df_credit, hue='Class')\n",
    "plt.title(\"Amounts by Hour of Frauds and Normal Transactions\", fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "72bdaa56-f8c2-4002-ab88-93a916942985",
    "_uuid": "83e8171418539dc0f1baf341d1e40a06d024cf0e"
   },
   "source": [
    "<h2>I will use boxplot to search differents distribuitions: </h2>\n",
    "- We are searching for features that diverges from normal distribuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "85d2a3c7-1673-436c-98f5-b298d1e1fd01",
    "_uuid": "1cf561af23615f8a5a1815a30841ed3a381f7616"
   },
   "outputs": [],
   "source": [
    "#Looking the V's features\n",
    "columns = df_credit.iloc[:,1:29].columns\n",
    "\n",
    "frauds = df_credit.Class == 1\n",
    "normals = df_credit.Class == 0\n",
    "\n",
    "grid = gridspec.GridSpec(14, 2)\n",
    "plt.figure(figsize=(15,20*4))\n",
    "\n",
    "for n, col in enumerate(df_credit[columns]):\n",
    "    ax = plt.subplot(grid[n])\n",
    "    sns.distplot(df_credit[col][frauds], bins = 50, color='g') #Will receive the \"semi-salmon\" violin\n",
    "    sns.distplot(df_credit[col][normals], bins = 50, color='r') #Will receive the \"ocean\" color\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(str(col))\n",
    "    ax.set_xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f10dc0eb4fc87a83bdfaff69f05d891ef7a753ad"
   },
   "source": [
    "  ## Diference in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40acff28e6f451b4951fc350721c48bb814f4557"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "77f8e91fce7e276d294101cefc2868c3d872e49d"
   },
   "source": [
    "## Feature selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "059645e4-56a8-474f-8211-bae661dd3b31",
    "_uuid": "9b558ff7c01aca62cbef47ff9a11fe496a642c65"
   },
   "outputs": [],
   "source": [
    "#I will select the variables where fraud class have a interesting behavior and might can help us predict\n",
    "\n",
    "df_credit = df_credit[[\"Time_hour\",\"Time_min\",\"V2\",\"V3\",\"V4\",\"V9\",\"V10\",\"V11\",\"V12\",\"V14\",\"V16\",\"V17\",\"V18\",\"V19\",\"V27\",\"Amount\",\"Class\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0a7a06c828b0091fa897f2cabb37085fd9c7db68"
   },
   "source": [
    "## Some Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3c3e1a2a1d82ff05f4a3dfde2ea9fa2eda88c9f7"
   },
   "outputs": [],
   "source": [
    "df_credit.Amount = np.log(df_credit.Amount + 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4f6f7871-6749-40b2-a143-b2c711a1d687",
    "_uuid": "67eb863cb3a7cf51b2f88e6a3134f4bb16c97322"
   },
   "outputs": [],
   "source": [
    "#Looking the final df\n",
    "df_credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8030913f-8791-4191-b0f0-113b0279cd24",
    "_uuid": "457bd7b63f6436b850d3bb08dd9b5cd07ca0ce74"
   },
   "outputs": [],
   "source": [
    "colormap = plt.cm.Greens\n",
    "\n",
    "plt.figure(figsize=(14,12))\n",
    "\n",
    "sns.heatmap(df_credit.corr(),linewidths=0.1,vmax=1.0, \n",
    "            square=True, cmap = colormap, linecolor='white', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "abec3a5e851cfd368f767cbd5322048951b52342",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a359ba0d-ee52-4c27-a8da-2f4fd4af1686",
    "_uuid": "be39107b6bd667eed64c66ca21dd7060030832a5"
   },
   "outputs": [],
   "source": [
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb # To do our transformation in a unique time\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, fbeta_score, confusion_matrix, precision_recall_curve, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "70d2acba0f36910bcea354dcad557db01dd529c0"
   },
   "outputs": [],
   "source": [
    "X = df_credit.drop([\"Class\"], axis=1).values #Setting the X to do the split\n",
    "y = df_credit[\"Class\"].values # transforming the values in array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0e3d1d0e-82ea-4f88-85bd-71350092c432",
    "_uuid": "eca22f092acc6bfc0012eaef482c60e0b794084d"
   },
   "outputs": [],
   "source": [
    "# the function that we will use to better evaluate the model\n",
    "def print_results(headline, true_value, pred):\n",
    "    print(headline)\n",
    "    print(\"accuracy: {}\".format(accuracy_score(true_value, pred)))\n",
    "    print(\"precision: {}\".format(precision_score(true_value, pred)))\n",
    "    print(\"recall: {}\".format(recall_score(true_value, pred)))\n",
    "    print(\"f2: {}\".format(fbeta_score(true_value, pred, beta=2)))\n",
    "\n",
    "# splitting data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2, test_size=0.20)\n",
    "\n",
    "classifier = RandomForestClassifier\n",
    "\n",
    "# build model with SMOTE imblearn\n",
    "smote_pipeline = make_pipeline_imb(SMOTE(random_state=4), \\\n",
    "                                   classifier(random_state=42))\n",
    "\n",
    "smote_model = smote_pipeline.fit(X_train, y_train)\n",
    "smote_prediction = smote_model.predict(X_test)\n",
    "\n",
    "#Showing the diference before and after the transformation used\n",
    "print(\"normal data distribution: {}\".format(Counter(y)))\n",
    "X_smote, y_smote = SMOTE().fit_sample(X, y)\n",
    "print(\"SMOTE data distribution: {}\".format(Counter(y_smote)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eb77e89a2a627b6ba3214e6097f44b90825495c3"
   },
   "source": [
    "## Evaluating the model SMOTE + Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b59e7374-c2e3-463e-9282-b2a8618b0bba",
    "_uuid": "e7fbae91fd27f70444187aeffdf6b28900b8d7d9"
   },
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, smote_prediction))\n",
    "\n",
    "print('\\nSMOTE Pipeline Score {}'.format(smote_pipeline.score(X_test, y_test)))\n",
    "\n",
    "print_results(\"\\nSMOTE + RandomForest classification\", y_test, smote_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9349261d-9aa6-475c-8e91-08d3d131c8ef",
    "_uuid": "6597b929123cd9484899aae93dd8205733050153"
   },
   "outputs": [],
   "source": [
    "# Compute predicted probabilities: y_pred_prob\n",
    "y_pred_prob = smote_pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate precision recall curve values: precision, recall, thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(precision, recall)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "65704d49-e64a-48e3-90f2-e815b970c0fe",
    "_uuid": "a0e228da0e4961f6c8c81e223310949e36a03547",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "# This ROC Curve is a overfitted curve, how can I fix this problem and get a correct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c1d92d6ef3bd9ce6ca2353c46cebadf0b138c0b6"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import KFold, cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d42aa55f72f6af5f217291a3396629b61e60f2cb"
   },
   "outputs": [],
   "source": [
    "#params of the model\n",
    "param_grid = {\"max_depth\": [3,5, None],\n",
    "              \"n_estimators\":[3,5,10],\n",
    "              \"max_features\": [5,6,7,8]}\n",
    "\n",
    "# Creating the classifier\n",
    "model = RandomForestClassifier(max_features=3, max_depth=2 ,n_estimators=10, random_state=3, criterion='entropy', n_jobs=1, verbose=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "27aeab7ea786aa0984556c080f290ecdf4cd82cc"
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(model, param_grid=param_grid, cv=5, scoring='recall')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "18b923f5e8887824e8a756a780322eb191c26bd6"
   },
   "outputs": [],
   "source": [
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "08366cf459d4a64a237ad6569475fddf288d6c68"
   },
   "outputs": [],
   "source": [
    "# Running the fit\n",
    "rf = RandomForestClassifier(max_depth=5, max_features = 7, n_estimators = 10)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98cc43256d3c18f65184461ba946ff53d747c12b"
   },
   "outputs": [],
   "source": [
    "# Printing the Training Score\n",
    "print(\"Training score data: \")\n",
    "print(rf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "31601b54a2bb41e3ea7771a84f3b4246c0f073c5"
   },
   "outputs": [],
   "source": [
    "#Testing the model \n",
    "#Predicting by X_test\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print_results(\"RF classification\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5c7f703380f3fb6fd2009a5b9a28fa7afa40b5e"
   },
   "source": [
    "## Feature importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e00f2c43f74d5dc315cea3c50a659db53577f0c"
   },
   "outputs": [],
   "source": [
    "features = [\"Time_min\", 'Time_hours',\"V2\",\"V3\",\"V4\",\"V9\",\"V10\",\"V11\",\"V12\",\"V14\",\"V16\",\"V17\",\"V18\",\"V19\",\"V27\",\"Amount\"]\n",
    "\n",
    "# Credits to Gabriel Preda\n",
    "# https://www.kaggle.com/gpreda/credit-card-fraud-detection-predictive-models\n",
    "plt.figure(figsize = (9,5))\n",
    "\n",
    "feat_import = pd.DataFrame({'Feature': features, 'Feature importance': rf.feature_importances_})\n",
    "feat_import = feat_import.sort_values(by='Feature importance',ascending=False)\n",
    "\n",
    "g = sns.barplot(x='Feature',y='Feature importance',data=feat_import)\n",
    "g.set_xticklabels(g.get_xticklabels(),rotation=90)\n",
    "g.set_title('Features importance - Random Forest',fontsize=20)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ba3059d6bd461704ccbcb844c127c62820bafe4"
   },
   "source": [
    "## ROC CURVE - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f73198cf5d3098187fe53e309f6ae3a3ba8197b"
   },
   "outputs": [],
   "source": [
    "#Predicting proba\n",
    "y_pred_prob = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate precision recall curve values: precision, recall, thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(precision, recall)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c7ce1bd11c6fb90646ade401146de8514577f057"
   },
   "outputs": [],
   "source": [
    "results = cross_val_score(rf,X_train, y_train, cv=10, scoring='recall')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b74333d678e1615fba83f6ffcf8d22229ab5b9db"
   },
   "source": [
    "## Modelling Logistic Regression with Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "706a2362ed34fee51188fa84b53c245bee2517a5"
   },
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.01, 0.1, 1, 10],\n",
    "             'penalty':['l1', 'l2']}\n",
    "\n",
    "logreg = LogisticRegression(random_state=2)\n",
    "\n",
    "grid_search_lr = GridSearchCV(logreg, param_grid=param_grid, scoring='recall', cv=5)\n",
    "\n",
    "grid_search_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c928f9d7f73c74def33abe7df3cb943e9e358b46"
   },
   "outputs": [],
   "source": [
    "# The best recall obtained\n",
    "print(grid_search_lr.best_score_)\n",
    "#Best parameter on trainning set\n",
    "print(grid_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5c191c97819f2ec6341a8d7f73ba51b44e92a716"
   },
   "source": [
    "### Setting the best parameters as parameters of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bdf9c84c574653bb1b089cce6cf137b5434f3ae8"
   },
   "outputs": [],
   "source": [
    "# Creating the model \n",
    "logreg = LogisticRegression(C=10, penalty='l2',random_state=2)\n",
    "\n",
    "#Fiting the model\n",
    "logreg.fit(X_train, y_train)\n",
    "           \n",
    "# Printing the Training Score\n",
    "print(\"Cross Validation of X and y Train: \")\n",
    "print(cross_val_score(logreg,X_train, y_train, cv=5, scoring='recall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7677137a08bfe32d134f5fb3da88c7a7451ab06e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predicting with the best params\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\")\n",
    "print_results(\"LogReg classification\", y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ca734b7b568210f64dcf77212ccf7d63095631a1"
   },
   "source": [
    "## Precision Recall Curve of Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dead578c8ce660b1d1456a942df41519d32dec86"
   },
   "outputs": [],
   "source": [
    "#Predicting proba\n",
    "y_pred_prob = logreg.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Generate precision recall curve values: precision, recall, thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(precision, recall)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e95b38a00d44be9d4fdb83f453a7b60da07b997e"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
