{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f6142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Step 1: Import Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f88327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 2: Load the Dataset\n",
    "data = pd.read_csv(\"../creditcard.csv\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = data.drop(columns=\"Class\", axis=1)\n",
    "y = data[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef192b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 3: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415bcb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 4: Create Pipeline and Train Model\n",
    "model_pipeline = Pipeline(\n",
    "    [(\"scaler\", StandardScaler()), (\"log_reg\", LogisticRegression(solver=\"lbfgs\"))]\n",
    ")\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088a1f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 5: Save the Pipeline to File\n",
    "joblib.dump(model_pipeline, \"fraud_detection_model.pkl\")\n",
    "\n",
    "print(\"âœ… Model saved as 'fraud_detection_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa32ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 6: Load the Saved Model\n",
    "loaded_model = joblib.load(\"fraud_detection_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42fc1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 7: Make Predictions on New Data (Fixed to avoid warning)\n",
    "# Take one sample from test set\n",
    "sample = X_test.iloc[0:1]  # Keep it as DataFrame, not NumPy array\n",
    "\n",
    "# Predict using loaded model\n",
    "prediction = loaded_model.predict(sample)\n",
    "\n",
    "print(\"Prediction (0 = Not Fraud, 1 = Fraud):\", prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a25cc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Step 8: Check Model Accuracy (Optional but good for confirmation)\n",
    "accuracy = loaded_model.score(X_test, y_test)\n",
    "print(f\"âœ… Model accuracy on test data: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd66973",
   "metadata": {},
   "source": [
    "### Prediction Widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6d03df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ Required imports\n",
    "import joblib\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be387a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# Refit the scaler on X_train\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, \"scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49710278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Refit the model (on the scaled X_train)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"fraud_detection_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2d835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# Refit the scaler on X_train\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "# Refit the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, \"fraud_detection_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22aca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"../creditcard.csv\")\n",
    "\n",
    "# Use only the selected 4 features\n",
    "selected_features = [\"Amount\", \"V14\", \"V10\", \"V12\"]\n",
    "X = df[selected_features]\n",
    "y = df[\"Class\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train the logistic regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Save the model and the scaler\n",
    "joblib.dump(model, \"fraud_detection_model.pkl\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "print(\"âœ… Model and Scaler saved for 4 features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c85af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Load model and scaler\n",
    "model = joblib.load(\"fraud_detection_model.pkl\")\n",
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "\n",
    "# Output widget to display results\n",
    "output = widgets.Output()\n",
    "\n",
    "\n",
    "# Prediction function\n",
    "def predict_new_transaction(amount, v14, v10, v12):\n",
    "    new_data = np.array([[amount, v14, v10, v12]])\n",
    "    new_data_scaled = scaler.transform(new_data)\n",
    "    prediction = model.predict(new_data_scaled)\n",
    "    with output:\n",
    "        clear_output()  # Clear previous output\n",
    "        print(\"Prediction (0 = Not Fraud, 1 = Fraud):\", prediction[0])\n",
    "\n",
    "\n",
    "# Input widgets\n",
    "amount_input = widgets.FloatText(description=\"Amount\")\n",
    "v14_input = widgets.FloatText(description=\"V14\")\n",
    "v10_input = widgets.FloatText(description=\"V10\")\n",
    "v12_input = widgets.FloatText(description=\"V12\")\n",
    "\n",
    "predict_button = widgets.Button(description=\"Predict\")\n",
    "\n",
    "\n",
    "def on_click(b):\n",
    "    predict_new_transaction(\n",
    "        amount_input.value, v14_input.value, v10_input.value, v12_input.value\n",
    "    )\n",
    "\n",
    "\n",
    "predict_button.on_click(on_click)\n",
    "\n",
    "# Display everything\n",
    "display(amount_input, v14_input, v10_input, v12_input, predict_button, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
